\section{Methodology}

\subsection{Dynamic Graph Representation}
We represent the transportation system at snapshot time $t$ as a directed multi-relational graph
\[
G_t = \big(V_t, E_t, \{A_t^{(\rho)}, W_t^{(\rho)}\}_{\rho\in\mathcal{R}}\big),
\]
where:
\begin{itemize}
    \item $V_t = V^j \cup V_t^v$ is the set of nodes at time $t$, consisting of
        \begin{itemize}
            \item $V^j$: static junction nodes, representing intersections in the road network,
            \item $V_t^v$: dynamic vehicle nodes, representing vehicles present at time $t$.
        \end{itemize}
    \item $E_t$ is the set of directed edges at time $t$, partitioned by relation type $\rho$.
    \item $\mathcal{R}$ is the set of relation types (road, traversal, interaction).
    \item $A_t^{(\rho)} \in \{0,1\}^{|V_t|\times |V_t|}$ is the binary adjacency matrix for relation $\rho$ at time $t$.
    \item $W_t^{(\rho)} \in \mathbb{R}_{\ge 0}^{|V_t|\times |V_t|}$ is the optional weighted adjacency for relation $\rho$ (e.g., distance-based interaction weights).
\end{itemize}

We define three relation types:
\begin{enumerate}
    \item \textbf{Road edges ($\rho=\text{road}$):} For adjacent junctions $(u,v)$ with legal direction $u\!\to\!v$, we add $(u,v)\in E_t^{(\text{road})}$, encoding static road topology.
    \item \textbf{Traversal edges ($\rho=\text{trav}$):} If vehicle $v_i^t$ occupies segment $(a,b)$, we add $(a,v_i^t)$ and $(v_i^t,b)$, linking the vehicle to its upstream and downstream junctions.
    \item \textbf{Interaction edges ($\rho=\text{inter}$):} For vehicles $v_i^t,v_j^t$ on the same segment with spacing $d_{ij}(t)\le\varepsilon$ and aligned headings, we add $(v_i^t,v_j^t)$ weighted by $\omega(d_{ij}(t)) = e^{-d_{ij}(t)/\lambda}$.
\end{enumerate}

Each node and edge carries feature vectors capturing static attributes (e.g., number of lanes, road type), dynamic states (e.g., vehicle speed, occupancy), and local traffic interactions.

\paragraph{Route intent.}
In addition to graph-based relations, each vehicle node includes a feature called \texttt{vehicle\_route\_left}, which encodes the sequence of upcoming edges along its pre-computed source--destination path. 
This representation explicitly provides route intent, ensuring predictions are conditioned on the actual trajectory a vehicle will follow rather than an inferred path. 
The sequence is later processed by a Route Encoder, described below.

\subsection{Temporal Windowing}
ETA prediction requires reasoning over temporal dynamics. We construct a window of $H$ consecutive snapshots:
\[
\mathcal{G}_{t-H+1:t} = \{G_\tau\}_{\tau=t-H+1}^t,
\]
where $H=30$ in our experiments (30-second interval). The prediction target is the ETA of vehicles present in the final snapshot $G_t$.

\subsection{Model Architecture}
Our Dynamic Graph Neural Network (DGNN) integrates spatial, temporal, and route information. The main components are:

\begin{itemize}
    \item \textbf{Graph Encoder:} Each snapshot $G_t$ is processed by a multi-layer GATv2-based encoder with residual connections and edge features, producing embeddings for junction and vehicle nodes.
    \item \textbf{Temporal Aggregator:} The sequence of snapshot embeddings is summarized into fixed-size context vectors by concatenating the mean of junction embeddings and the mean of vehicle embeddings at each step. A GRU then processes the resulting sequence of $H$ context vectors to produce a history-aware temporal context. This vector is broadcast to all vehicles at $t^*$, allowing each prediction to incorporate recent traffic evolution.
    \item \textbf{Vehicle Selection:} From the final snapshot $G_t$, we retain only vehicle node embeddings, as these are the prediction targets for ETA.
    \item \textbf{Route Encoder:} Each vehicleâ€™s remaining route (the \texttt{vehicle\_route\_left} feature) is embedded via an edge-ID embedding with mean pooling, then concatenated with its vehicle embedding.
    \item \textbf{Fusion and MoE Head:} Vehicle embeddings, enriched with route and temporal context, are fused through a feed-forward network and routed to a sparse Top-$k$ Mixture-of-Experts (MoE) head, where specialized experts capture heterogeneous traffic regimes. The output is the ETA prediction for each vehicle.
\end{itemize}

% ===== TikZ Diagram of Model Architecture =====
\begin{figure}[t]
    \centering
    \resizebox{0.95\columnwidth}{!}{%
    \input{figures/fig_temporal_moe_eta.tikz}%
    }
    \caption{Temporal MoE ETA model. A window of $T{=}30$ dynamic graph snapshots (shown as an overlapped deck) is processed by a \emph{shared} Graph Encoder; prediction is made at the last snapshot $t^*$. In the Full variant, a Route Encoder summarizes each vehicle's remaining path before Fusion and a Top-$k$ MoE head produces per-vehicle ETA.}
    \label{fig:temporal-moe-eta}
\end{figure}
\subsection{Loss Functions and Training Protocol}
We train the model with supervised regression on ETA targets using mean absolute error (MAE) in seconds:
\[
\mathcal{L}_{\text{MAE}} = \frac{1}{N}\sum_{i=1}^N \big| \hat{y}_i - y_i \big|,
\]
where $\hat{y}_i$ and $y_i$ are the predicted and true ETAs. Additional evaluation metrics include RMSE, weighted absolute percentage error (WAPE), and percentile errors (P50, P90, P95). 
All experiments are run on the same dataset splits, enabling consistent comparisons.


\subsection{Loss Functions and Training Protocol}
We train the model with supervised regression on ETA targets using mean absolute error (MAE) in seconds:
\[
\mathcal{L}_{\text{MAE}} = \frac{1}{N}\sum_{i=1}^N \big| \hat{y}_i - y_i \big|,
\]
where $\hat{y}_i$ and $y_i$ are the predicted and true ETAs. Additional evaluation metrics include RMSE, weighted absolute percentage error (WAPE), and percentile errors (P50, P90, P95). 

The dataset spans four simulated weeks of traffic. We partition this chronologically into two weeks for training, one week for validation, and one week for testing. This split ensures that models are evaluated on non-overlapping time intervals that include different traffic patterns (rush hours, weekends, and long trips).

\paragraph{Ablation Variants.}
To quantify the contribution of each modeling component, we design several controlled ablations:
\begin{itemize}
    \item \textbf{None (structural baseline):} Road edges only; static features.
    \item \textbf{Weak (interaction-aware):} Adds dynamic traversal and interaction edges.
    \item \textbf{Medium (demand-aware):} Adds aggregate route-related features (e.g., edge route counts).
    \item \textbf{Full (intent-aware):} Adds explicit route encoder over each vehicle's remaining path (\texttt{vehicle\_route\_left}).
    \item \textbf{Full+Temporal:} Extends Full by concatenating a GRU-based temporal context aggregated from past snapshots.
    \item \textbf{Full+Memory:} Further extends Full+Temporal with a memory mechanism that accumulates historical contexts across windows, capturing longer-range dependencies beyond the local horizon.
\end{itemize}
All variants share the same training protocol and data splits, enabling a controlled comparison of structural, dynamic, demand, intent, and temporal features.
