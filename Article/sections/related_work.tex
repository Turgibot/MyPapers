\section{Related Work}

\subsection{Classical pathfinding and routing}
On static graphs $G=(V,E)$ with non-negative edge costs, shortest paths are classically computed via Dijkstra’s algorithm~\cite{dijkstra1959}. Alternatives such as Bellman–Ford~\cite{bellman1958routing} and bidirectional search~\cite{pohl1971bi} trade efficiency for generality. More advanced techniques such as A*/ALT landmarks~\cite{goldberg2005}, Contraction Hierarchies~\cite{geisberger2008}, and Customizable Route Planning~\cite{delling2011} scale to web applications but rely on static edge-time models. As a result, they fail to capture evolving congestion or vehicle interactions. Our approach differs fundamentally by learning ETA directly from dynamic traffic graphs rather than static cost assumptions.

\subsection{Learning-based ETA and traffic forecasting}
The proliferation of urban mobility datasets motivated machine learning methods for ETA. Gradient boosting models such as XGBoost~\cite{chen2016xgboost} leverage handcrafted features (trip distance, time-of-day) and perform well on aggregated taxi records (e.g., NYC, Porto~\cite{nyc_tlc,moreira2013porto}), but they cannot capture fine-grained spatio-temporal interactions.

Deep learning approaches address this gap. \textbf{DeepTTE}~\cite{deepTTE2018} pioneered end-to-end trajectory-based ETA using CNN–RNN encoders over GPS traces, reporting mean absolute errors of about 2.5 minutes for short urban trips. \textbf{STANN}~\cite{stann2021} introduced spatio-temporal attention mechanisms, reducing MAE to 32 seconds on short ride-hailing trips. \textbf{ConSTGAT}~\cite{constgat2020} extended graph attention to traffic ETA, achieving MAEs of 40–60 seconds for Chengdu taxi trips under 15 minutes. These results illustrate the growing impact of attention-based architectures. However, they treat the road network as largely static and do not incorporate explicit route-left path features. Our model addresses this by embedding the remaining trip explicitly into the graph representation.

\subsection{Spatio-temporal graph neural networks}
Graph neural networks advanced traffic forecasting by modeling sensor networks as spatio-temporal graphs. \textbf{DCRNN}~\cite{dcrnn2018} combined diffusion graph convolutions with recurrent units, achieving state-of-the-art traffic speed prediction on METR-LA and PEMS-BAY (5-min MAE $\approx$ 10s, 60-min MAE $\approx$ 3 min). These works demonstrate the power of STGNNs but typically operate on fixed sensor nodes rather than vehicle-level interactions. In contrast, our dynamic graph explicitly models vehicles as nodes, connected through time-varying junction and interaction edges.

\subsection{State-of-the-art production models}
Most recently, \textbf{DuETA}~\cite{dueta2023} introduced duration-aware ETA modeling at Baidu Maps, categorizing trips into short (0–3 km), medium (3–10 km), and long (>10 km). DuETA achieved MAEs of 27s, 46s, and 98s respectively across these categories, significantly improving upon prior baselines. Unlike DuETA, which relies on trip segmentation, our method unifies all trip types under a single dynamic spatio-temporal framework. By incorporating route-left path features directly into the graph, our model can generalize across short and long trips without predefined bins.

\subsection{Summary}
Overall, prior work highlights the value of sequential modeling (DeepTTE), spatio-temporal attention (STANN, ConSTGAT), graph diffusion (DCRNN), and duration-aware embeddings (DuETA). However, none fully integrate explicit pre-planned routes and vehicle–junction dynamics. Our contribution is to unify these aspects into a single dynamic spatio-temporal graph with route-left features and mixture-of-experts specialization, bridging the gap between trajectory-based and graph-based ETA prediction.
